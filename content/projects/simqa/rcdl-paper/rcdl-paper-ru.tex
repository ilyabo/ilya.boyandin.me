\documentclass{article}
\usepackage{graphicx} % Required for inserting images

\title{rcdl}
\author{Ilya Boyandin}
\date{October 2003}

\usepackage{amsmath}
\usepackage[english, russian]{babel}

\title{Преобразование запросов для предметно-независимого фактографического поиска в Интернет}
\author{Илья Бояндин, Игорь Некрестьянов}
\institution{
Санкт-Петербургский Государственный Университет
}
\newcommand{\query}[1]{``{\textrm{\tt #1}}''}

\begin{document}
\maketitle

\begin{abstract}
В работе рассматривается задача преобразования вопросов, задаваемых
пользователями предметно-независимой системы фактографического поиска в Веб 
на естественном языке, в запросы поисковой системы общего 
назначения. 

Анализируется работа статистического алгоритма преобразования запросов,
основанного на модели QASM~\cite{qa:radev:qasm}.
%который автоматически обучается методам преобразования запросов,
%и предлагается его модификация.
%Анализируется работа статистического алгоритма преобразования запросов,
%основанного на модели QASM~\cite{qa:radev:qasm}.
Оценка качества поиска с использованием предлагаемого алгоритма
производится на реальных русскоязычных фактографических запросах из журнала
поисковой системы Яндекс.

\end{abstract}


\section{Введение}

Задача фактографического поиска --- это разновидность задачи текстового
поиска с уменьшенной гранулярностью \cite{irg:websearch}. В отличие от
классической задачи поиска при фактографическом поиске
необходимо обнаружить не документы на тему запроса,
а точные и лаконичные ответы на конкретные вопросы, сформулированные на естественном
языке. Например, на вопрос: ``Кто был первым космонавтом?'' идеальная
система фактографического поиска должна выдавать единственный ответ: ``Юрий
Гагарин''.

В отличие от вопросно-ответных систем с активным усвоением
знаний от систем предметно-независимого фактографического поиска не требуется способность
производить логический вывод -
система должна лишь выделить из набора данных короткий фрагмент текста,
который является ответом на вопрос. 
Поэтому результат работы такой системы сильно зависит от набора текстовых
данных, в которых производится поиск. Например, если 
поиск ответа на тот же вопрос о первом космонавте производится в коллекции 
текстов об американской космонавтике,
то правильным ответом вполне может оказаться ``Алан Шепард''.

На данный момент в Интернет отсутствуют промышленные системы,
способные автоматически обрабатывать фактографические запросы с
приемлемым качеством. Но потребность в обработке таких запросов
несомненно существует. Согласно результатам анализа журнала поисковой
системы Excite\footnote{за 20 декабря 1999 года} около 8\% пользовательских
запросов являются 
%вопросами в естественной форме на английском языке~
корректными вопросами английского языка,
из них около 44\% --- фактографическими~\cite{qa:Tritus}.
Пользователи русскоязычной поисковой системы Яндекс тоже нередко формулируют
свои запросы в виде корректных вопросов~\cite{yandex:voprosy}.

Актуальность задачи фактографического поиска стимулирует активные
исследования в этой области. В частности, в рамках конференции TREC 
уже несколько лет существует отдельная дорожка, посвященная 
экспериментальной оценке систем фактографического поиска~\cite{qa:TREC8:evaluation}.

Огромный объем постояно обновляемой и пополняемой текстовой 
информации в Интернет дает системам фактографического поиска
потенциальную возможность находить ответы на гораздо более разнообразные
фактографические вопросы, чем это возможно в рамках закрытой 
коллекции документов. 

Однако данные в Интернет из-за отсутствия централизованного
контроля над публикацией обладают рядом особенностей, осложняющих решение
задачи поиска: неструктурированностью, разнородностью, противоречивостью.
С другой стороны, 
в Интернет также наблюдается избыточность, повторяемость данных:
ответ на один и тот же вопрос, по-разному сформулированный, может содержаться
в десятках документов. Как было отмечено рядом исследователей, 
эта избыточность может быть использована
для повышения качества фактографического
поиска~\cite{qa:dumais:redundancy,qa:clarke:redundancy}, 
что косвенно подтверждают результаты 
экспериментов по выявлению зависимости качества фактографического 
поиска от размера коллекции данных~\cite{qa:clarke:corpus_size_impact,qa:clarke:web_reinforced}.

Обработка запроса в системе фактографического поиска
обычно производится в несколько этапов~\cite{qa:Mulder}:
\begin{enumerate}
\item {\bf Предварительный} \\
На этом этапе обычно выполняется
классификация вопроса, на основе результатов
которой, формулируется запрос и определяются возможные формы ответов.

\item {\bf Преобразование вопроса} \\
Вопрос преобразуется в один или несколько запросов поисковой системы,
так чтобы найденные документы как можно точнее представляли
документы коллекции, в которых содержатся возможные ответы.
%поисковой системой документов было
%как можно больше содержащих ответ на вопрос.

\item {\bf Текстовый поиск} \\
Поисковая система, используя традиционные методы информационного поиска,
находит документы коллекции, соответствующие сформулированным запросам.

\item {\bf Выделение ответов} \\
Из найденных поисковой системой документов выбираются
небольшие фрагменты текста, содержащие наиболее вероятные ответы.
Системы пытаются различными способами убедиться в правильности каждого из возможных
ответов-кандидатов и отбросить ``неубедительные''.
%Некоторые системы способны выделять в документах точные ответы, а не фрагменты текста.
\end{enumerate}

Существующие в Интернет поисковые системы общего назначения могут быть
эффективно использованы системой фактографического поиска
на этапе текстового поиска для обнаружения
документов с возможными ответами~\cite{qa:radev:getting_answers}.
Например,
запрос \query{Набоков /1 !родился}, посланный Яндекс,
дает пять правильных ответов (в 1899 году) из первых пяти, 
тогда как среди первых пяти документов, полученных по запросу \query{Когда родился Набоков?},
только один содержит правильный 
ответ\footnote{Описанный эксперимент с Яндекс проводился 15
марта 2003}.
Качество преобразования вопроса в запрос поисковой системы
в значительной мере определяет общее качество поиска. % системы фактографического поиска.
Действительно, если ни один документ,
содержащий искомый ответ, не будет найден при помощи построенных запросов, 
то последующие этапы никак не смогут исправить ситуацию;
если же несколько найденных документов будут содержать правильный ответ,
это повысит вероятность его выбора системой на этапе выделения ответов\footnote{
Во многих системах (например, в системе Mulder~\cite{qa:Mulder})
оценки для возможных ответов на этапе выделения ответов
вычисляются таким образом, что вероятность
выделения ответа, чаще присутствующего в найденных документах, повышается.
}.
%это упростит работу системы на этапе выделения ответов.
%система может убедиться в его правильности и
%выдать в итоге именно правильный, а не другой возможный ответ.

%Драгомир Радев и др. предложили алгоритм QASM~\cite{qa:radev:qasm},
%обучающийся наилучшим преобразованиям вопросов
%в запросы поисковой системы общего назначения на наборе вопросов и ответов.

Целью этой работы было исследование возможности эффективного
преобразования вопросов на основе статистических методов. 
На сегодняшний день наилучшие результаты фактографического поиска обеспечивают
системы, активно использующие методы работы с текстами на естественном языке, 
но как показал пример системы Tritus\cite{qa:Tritus}, системы использующие 
статистические методы и очень простые знания о языке,
могут достигать значительных результатов.

Использование статистических подходов зачастую позволяет 
значительно снизить вычислительную
трудоемкость обработки запроса и, как следствие, повысить масштабируемость 
системы. Другое важное преимущество статистического подхода --- уклонение от 
необходимости использования высококачественных лингвистических ресурсов,
доступность которых, например, для русского языка ограничена.

В качестве отправной точки наших исследований был использован алгоритм 
QASM~\cite{qa:radev:qasm}, который
обучается преобразованиям вопросов на наборе вопросов и ответов.
Начав с модели QASM, мы попытались найти ответы на ряд вопросов:
какова максимальная достижимая эффективность преобразований в этой
модели? насколько отличается эффективность операторов и свойств? 
от каких факторов зависит оптимальный выбор?

Дальнейшее изложение имеет следующую структуру:
в разделе 2 представлен обзор близких работ,
в разделе 3 описан базовый алгоритм QASM, 
а в разделе 4 --- используемые нами модификации алгоритма.
В разделе 5 изложены наиболее важные характеристики 
прототипа системы фактографического поиска,
анализ результатов экспериментов с которым представлен в разделе 6.

%---------------------------- Related work -------------------------------------

\section{Близкие работы}

\begin{table*}
\begin{center}
\begin{tabular}{|l|l|}
\hline
Вопрос & Тип вопроса \\
\hline
Как зовут создателя логотерапии? & ЛИЧНОСТЬ \\
В каком году был построен Мавзолей в Берлине? & ДАТА \\
Где находится Тадж Махал? & МЕСТО \\
Каково расстояние от Абу-Даби до Агры? & РАССТОЯНИЕ \\
\hline
\end{tabular}
\caption{Примеры типов вопросов}
\label{table:qtypes}
\end{center}
\end{table*}

Преобразование запросов активно используется во многих задачах, связанных с
поиском информации. По типу цели преобразования их можно разделить на
два основных класса:
\begin{itemize}
\item {\bf ``Перевод'' запроса}\\
К этой группе относятся преобразования, которые предназначены для выражения
того же запроса в другом виде с максимальным сохранением свойств исходного запроса. 
Например, к этому классу относятся преобразования запросов посредником в метапоисковых системах
(где каждый из поисковых серверов может иметь свой язык запросов со 
специфичным синтаксисом и семантикой)~\cite{admire} или в системах многоязычного поиска
(где исходный запрос может автоматически переформулироваться на другом
языке)~\cite{qa:AnswerBus}.

\item {\bf ``Уточнение'' запроса}\\
Преобразования этого вида изначально ориентированы на изменение свойств 
запроса, то есть его семантики. Целью этого изменения обычно
является получение новой редакции запроса, которая лучше описывает 
информационную потребность, стоящую за исходным запросом. Такие
преобразования, например, часто используются вместе с механизмом 
обратной связи (relevance feedback) для итеративного уточнения
поисковой системой потребностей пользователя~\cite{baeza99modernir}.
\end{itemize}

В контексте предметно-независимого фактографического поиска особый
интерес представляют преобразования второго типа,
поскольку поисковые системы общего назначения не предназначены
для поиска ответов на вопросы естественного языка,
и для того чтобы правильно сформулировать на языке запросов поисковой системы
реальную информационную потребность пользователя,
необходимо изменить семантику исходного вопроса.
Например, некоторые слова, содержащиеся в вопросе, совсем не обязательно
должны содержаться в правильном ответе на этот вопрос:
они могут просто отсутствовать, присутствовать в другой форме или
их могут заменять синонимы или обобщающие понятия.

Преобразования вопросов в системах фактографического поиска
обычно можно представить в виде последовательности операций, таких как:
%удаление вопросительных слов;
добавление, удаление или замена слов, фраз или добавление
операторов синтаксиса поисковой системы,
морфологические преобразования слов и т.п. (см, например, \cite{qa:Mulder}).

Выбор операций преобразования, которые применяются к вопросу,
основывается на различных характеристиках
вопроса или отдельных слов, участвующих в вопросе.
Важнейшим свойством вопроса является его тип.
Наборы типов вопросов, используемые разными системами,
и методы их определения  различаются,
но в большинстве систем
тип вопроса задается объектом вопроса (см. таблицу~\ref{table:qtypes}),
который определяется
по вопросительным словам (см, например, \cite{qa:Tritus})
или при помощи более сложных синтаксического и семантического
разборов вопроса (см., например, \cite{qa:Harabagiu} или \cite{qa:clarke:passage}).
%(тем самым, возможно, подсказывая дополнительные слова, которые
%стоит добавить в запрос) (см., например, \cite{qa:Harabagiu).
%Некоторые системы определяют преобразования, которые применяются к вопросу,
%анализируя дерево синтаксического разбора вопроса (см., например,
%\cite{qa:clarke:passage}).
К характеристикам отдельных слов вопроса, которые используются
для определения преобразований, могут относиться:
роль слова (например, вопросительное или нет), часть речи,
значимость слова (оцениваемая на основе частоты его использования)
 и др.~\cite{qa:radev:qasm}
%список синонимов и обобщающих понятий.


Правила преобразования могут быть предопределены в системе заранее с разной
степенью обобщенности. Например, в работе~\cite{qa:soubbotin} формулируются
простые запросы, состоящие из наиболее ``важных'' по статистическим
свойствам ключевых слов вопроса. Этот подход обеспечивает невысокую
точность, но довольно хорошую полноту поиска\footnote{ 
Отметим, что такой подход значительно повышает нагрузку на последующие шаги
обработки фактографического запроса.
Хотя в этом случае система получает больше документов, содержащих
правильный ответ, %и вероятность его удачного извлечения повышается,
она также получает и
%кучу мусора документов, который может ввести ее в заблуждение.
значительно большее количество неподходящих документов,
которые могут ввести ее в заблуждение.
}. 

В системе Falcon~\cite{qa:Harabagiu} оптимальная 
степень ослабления запроса определяется динамически.
Получив результаты поиска по начальному запросу, система формулирует ослабленную 
версию запроса (удаляя некоторые слова), %или заменяя их на синонимы), 
если результатов найдено слишком мало,
или формулирует более строгий запрос (добавляя в него термы), если результатов слишком много.

В системе AskMSR~\cite{qa:dumais:redundancy} правила преобразования задаются вручную. 
Достаточно строгие правила, созданные вручную, могут обеспечивать высокую точность поиска.
Однако поскольку строгие правила чаще всего узкоспециализированы,
то есть применимы в весьма ограниченном наборе случаев,
то создание исчерпывающего набора таких правил,
учитывающего все особенности естественного языка, вряд ли возможно. %невозможно.


%В нем исходный запрос модифицируется с использованием термов, извлеченных из
%результатов поиска по немодифицированному запросу (локальный метод)
%или же уточняется самим пользователем (глобальный).

%%<Prioritized Keyword Matching>
%%В \cite{qa:sneiders:faqansw} подробно описывается, а
%В \cite{qa:soubbotin} применяется
%%для фактографического поиска,
%техника, при которой различаются несколько уровней
%важности термов вопроса: основные, второстепенные и несущественные.
%%Основные термы передают сущность вопроса, и не могут быть проигнорированы;
%%второстепенные помогают передать значение, но могут быть проигнорированы;
%%несущественные могут быть полностью проигнорированы.
%Основные термы включаются в преобразованный запрос, второстепенные используются
%впоследствии вместе с основными для выделения ответов,
%а несущественные отбрасываются.
%Одним из критериев важности терма является его частотность
%для набора документов, в котором выполняется поиск:
%чем реже терм встречается, тем он важней.
%%Подобная этой техника: удаление из длинных вопросов слов, которые встречаются чаще остальных
%%слов вопроса (не считая стоп-слов), используется при формулировании запросов в системе
%%AnswerBus \cite{qa:AnswerBus}.

В течение нескольких последних лет %все больше
много внимания уделяется
исследованию подходов, автоматически обучающихся преобразованиям
запросов (см., например, \cite{glover:learning_qms}),
в том числе и для фактографического поиска.
%в данном конкретном окружении~\cite{??}
%и не только в контексте
%фактографического поиска~\cite{glover:learning_qms}.

Система Tritus \cite{qa:Tritus} обучается правилам преобразования
фактографических вопросов на наборе ``часто задаваемых вопросов'' и ответов на них.
%вопросов и фрагментов текста, содержащих ответы.
При обучении система сначала пытается найти важные фразы, наиболее часто
встречающиеся в фрагментах текста, содержащих ответы на вопросы каждого
типа, взвешивая фразы с помощью весов, подобных $tfidf$, и строит
правила преобразований, используя эти фразы.
Затем система оценивает качество
всех полученных преобразований, применяя их ко всем вопросам
соответствующего типа из тренировочного набора,
передавая запросы поисковой системе и оценивая близость первых
$n$ найденных документов к известному ей ответу на вопрос, и выбирает и
запоминает только наилучшие преобразования.






%---------------------------- QASM -------------------------------------

\section{Алгоритм QASM}

%Вероятностный алгоритм QASM (Question Answering using Statistical Models)
%основан на предположении,
%что для каждого введенного пользователем вопроса $N$
%существует %единственный
%наилучший запрос $Q$ поисковой
%системы (из пространства $U_Q$ всех возможных запросов, которые могут
%быть получены из $N$ простыми операциями преобразования),
%с помощью которого
%%достигаются максимальные точность и полнота для исходного вопроса.
%достигается наибольшая эффективность.
%%(добавление/удаление/замена слов или фраз, добавление кавычек, добавление дизъюнкций взаимозаменяемых слов и др).
%Задача поиска наилучшего преобразования вопроса рассматривается,
%как проблема канала связи с помехами.
%Запрос $Q$ ``передается'' через зашумленный канал и преобразуется
%в вопрос $N$ естественного языка, который поступает на вход системы фактографического поиска.
%Задача системы: по данному вопросу $N$ восстановить ``исходный''
%запрос $Q$ из пространства $U_Q$.


Вероятностный алгоритм QASM (Question Answering using Statistical Models)~\cite{qa:radev:qasm}
обучается  преобразованиям, которые представляют собой композиции атомарных
преобразований. 

Задача алгоритма --- построить по входному вопросу последовательность
атомарных преобразований, композиция которых в применении к нему дает
наилучший запрос\footnote{В этой статье термин {\em вопрос}
используется для обозначения исходного вопроса пользователя на естественном
языке, а термин {\em запрос} чаще всего используется для обозначения
преобразованной версии вопроса,
которая отправляется поисковой системе.}.
Процедура построения запроса итеративна: на каждом шагу
выбирается атомарное преобразование, улучшающее запрос; итерации
продолжаются, пока улучшение возможно.

Для того чтобы алгоритм QASM мог строить преобразования вопросов,
ему необходимо пройти этап обучения,
на котором  он выявляет закономерности,
связывающие характеристики запроса и удачные преобразования.

%Предполагается, что для вопроса (или запроса) можно выбрать
%атомарный оператор, после применения которого к запросу, будет получен
%новый запрос, более эффективный, чем предыдущий. % (или по крайней мере, не менее эффективный).

Вообще говоря, задачу выбора атомарного оператора можно рассматривать как
задачу классификации: алгоритм должен решить, к какому классу отнести запрос
на данном шагу, и применить к нему атомарный оператор, соответствующий
выбранному классу. 



\subsection{EM-алгоритм}

В основе алгоритма обучения QASM лежит известный статистический алгоритм {\em максимизации ожидания}
(Expectation Maximization) --- итеративный алгоритм нахождения оценок
максимального правдоподобия.
%$\Theta$.
%Он позволяет получать оценки $\Theta$, максимизирующие функцию правдоподобия
%$L(\Theta;X):=p(X|\Theta)$, где $X=(x_1,\ldots,x_n)$ - данные результатов наблюдений.
%с одинаковым распределением, зависящим от $\Theta$.
Этот алгоритм часто используется в задачах с неполными данными. В нашем
случае при обучении известен только набор вопросов и ответов, а сами
преобразования, дающие наилучший результат для каждого из вопросов,
неизвестны.

EM-алгоритм состоит из следующих шагов:
%до тех пор пока не достигнут локальный максимум:
\begin{enumerate}
\item оцениваются неизвестные параметры (используются доступные алгоритму результаты измерений и данные модели),
\item модифицируется модель алгоритма (на основе полученных на шаге 1 оценок),
\item если не достигнут локальный максимум, то переходим к шагу 1.
\end{enumerate}

Известно, что EM-алгоритм с каждым шагом обеспечивает улучшение получаемых
оценок %$\Theta$
и в конце концов сходится \cite{dempster:em}.

%Отправляясь от начального значения $\Theta_0$, алгоритм повторяет следующие два шага,
%до тех пока не достигает локального максимума:
%\begin{enumerate}
%\item Шаг оценивания (E): оценить значения неизвестных параметров $Y$, используя значение $\Theta_{n-1}$
%и известные данные $X$
%\item Шаг максимизации (M): используя $\Theta_{n-1}$ и полученные оценки для $Y$, вычислить
%$\Theta_{n}$, максимизируя правдоподобие
%\end{enumerate}
%EM-алгоритм с каждым шагом обеспечивает улучшение оценки $\Theta$ и в конце концов
%сходится \cite{dempster:em}.

\subsection{Обучение}\label{qasm:learning}

QASM обучается на наборе вопросов и ответов,
пытаясь найти для каждого из вопросов тестового набора наилучшую последовательность
атомарных преобразований. Формально задачу можно поставить следующим образом.

Пусть $\mathcal{A}_1,\ldots, \mathcal{A}_l$ --- фиксированный набор 
функций ({\em свойств запросов}), сопоставляющих запросу целое число.
Упорядоченный набор численных значений всех этих функций для конкретного
запроса $q$ назовем контекстом $\mathcal{C}(q)$ запроса:
$$\mathcal{C}(q):=(\mathcal{A}_1(q),\ldots,\mathcal{A}_l(q))$$
Пусть $\mathcal{O}_1,\ldots, \mathcal{O}_m$ --- 
фиксированный набор {\em атомарных операторов преобразования} запросов,
сопоставляющих запросу $q$ новый запрос $\mathcal{O}_i(q)$, 
а $F(q)$ --- некоторая функция оценки {\em реального качества} запроса, которая может 
использовать информацию о найденных по этому запросу документах (см. раздел \ref{trdr}).

Отметим, что только оператор $Identity$, сопоставляющий запросу самого себя
($Identity(q)=q$), является фиксированным. Выбор других операторов, свойств и
функции $F(q)$ не влияет на общий алгоритм и зависит от его 
реализации.

Алгоритм обучения должен определить отображение $T$,
ставящее в соответствие любому набору
$\mathcal{C}(q)$ значений
свойств запроса $q$ номер $r$ атомарного оператора, 
приводящего к наиболее качественному преобразованию.

Другими словами, алгоритм обучения строит классификатор $T$,
который каждому допустимому контексту сопоставляет
класс, соответствующий одному из атомарных операторов, наилучшему для данного контекста.


%Переход от рассмотрения самих запросов к вычислению значений
%конечного набора их свойств значительно упрощает
%представление запросов и избавляет от необходимости хранить распределение вероятностей
%применения операторов по всем возможным запросам (которых, очевидно, бесконечно много).
%Запросы с одинаковыми значениями всех свойств обрабатываются алгоритмом одним и тем же образом.

%Задачу нахождения на каждом шагу наилучшего оператора, преобразующего данный запрос,
%можно рассматривать как задачу классификации:
%множество всех допустимых запросов разбивается на классы эквивалентности,
%содержащие запросы, для которых наилучшим является один и тот же оператор.


%\subsection{Обучение}
%При обучении QASM используется набор вопросов на естественном языке и правильных ответов на каждый
%из этих вопросов.
%В данном случае, при обучении известны лишь пары вопрос-ответ, но не сами преобразованные запросы,
%которые дают наилучший результат для каждого из вопросов.

%В качестве $\Theta$ берется матрица 

Отображение $T$ в алгоритме QASM задается матрицей
$$\Theta = \{p(\mathcal{O}_i|\mathcal{C}_j)\}_{i,j}$$
вероятностей $p(\mathcal{O}_i|\mathcal{C}_j)$
применения оператора $\mathcal{O}_i$ к запросу, задающему контекст $\mathcal{C}_j$:
\[
T(\mathcal{C}_j)=\underset{i}{argmax}(\Theta_{i,j})
\]
где $\mathcal{C}_j$ - допустимый контекст с номером $j$
(число всех допустимых контекстов конечно, поэтому их можно занумеровать).
Причем, $$\forall j : \sum_{i=0}^m p(\mathcal{O}_i|\mathcal{C}_j)=1$$



Матрица $\Theta$ инициализируется равномерным распределением 
по всем операторам. Далее,
алгоритм обучения последовательно выполняется для каждого из вопросов
тренировочного набора на одной и той же матрице $\Theta$:
\begin{enumerate}
\item 
Применить каждый из операторов к вопросу, оценивая качество
получаемых запросов (правильный ответ на исходный вопрос известен).
Если наибольшее качество обеспечивает оператор $Identity$,
то обработка текущего запроса завершена.
Иначе --- на основе распределения вероятностей, заданному в $\Theta$ для
контекста запроса,
выбрать оператор, который будет применен к запросу.

\item
Применить к запросу выбранный на первом шаге оператор.
Модифицировать $\Theta$, используя информацию о качестве
запросов, полученную на первом шагу:
\begin{itemize}
\item операторы упорядочиваются по убыванию качества получаемых
      запросов (для данного запроса $q$),
\item вероятности $p(\mathcal{O}_i|\mathcal{C}(q))$
      в строке $\Theta$, соответствующей $\mathcal{C}(q)$,
      домножаются на $\mathit{oprank}_{i}^{-1}$,
     где $\mathit{oprank}_i$ --- ранг $i$-го оператора
     (присвоенный ему в результате упорядочивания),
\item строки матрицы нормализуются, так чтобы сумма значений в строке
      равнялась 1.
\end{itemize}
\item
Если изменение матрицы $\Theta$ на этой итерации не превышает заданного порога
($\delta(\Theta) < \varepsilon$), то обработка текущего запроса
завершена, а построенная матрица $\Theta$ и есть результат обучения алгоритма.
Иначе цикл повторяется с первого шага.
\end{enumerate}

\subsection{Преобразование вопросов}
После того как обучение завершено, система может преобразовывать вопросы, которых не было
в тренировочном наборе.
Алгоритм преобразования вопросов QASM \cite{qa:radev:qasm}
сопоставляет вопросу преобразованный запрос,
последовательно вычисляя контекст запроса и применяя наиболее вероятный
(в соответствии с распределением, заданным в $\Theta$)
оператор к запросу,
снова пересчитывая контекст и выбирая оператор, и так
до тех пор пока в какой-то момент этим оператором не становится $Identity$
(или другой оператор, не изменяющий данный запрос).
Таким образом, на выходе система выдаст запрос $q_s$, где
$$q_k=\mathcal{O}_{T(\mathcal{C}(q_{k-1}))}(q_{k-1}),$$
$k\in 1:s$, а $q_0$-исходный вопрос.



\section{Модификации QASM} 

Кроме описанного в предудыщей секции оригинального алгоритма QASM 
мы рассматривали два альтернативных подхода, работающих в рамках 
той же модели.

\subsection{Оптимальный QASM (oQASM)}

Эта модификация QASM предназначена для оценки  максимально достижимого
результата при использовании модели QASM. Предполагается, 
что этот алгоритм всегда возвращает наилучшее преобразование 
вопроса, которое можно построить при заданом наборе атомарных
операторов.

Практическая реализация этого алгоритма была основана на 
полном переборе всех возможных преобразований
для каждого из вопросов тестового набора и 
выборе дающего наилучший результат.

Отметим, что эта оценка не является верхним пределом в общем случае,
т.к. весьма вероятно, что можно добиться лучшего результата
при использовании какого-либо другого набора атомарных операторов.

\subsection{Множественный QASM (mQASM)}\label{mqasm}

Оригинальный QASM генерирует только один преобразованный запрос по входному вопросу.
%Однако практическое применение подобного подхода
%к задаче фактографического поиска в Интернет показывает, 
Однако наши эксперименты показали,
что в силу нерегулярности данных в Интернет, даже для очень похожих запросов 
(неразличимых с точки зрения обученной модели) наилучший результат
могут обеспечивать разные преобразования. 
Например, такими запросами 
являются вопросы:
\query{Кто был лауреатом Нобелевской премии мира в 1975 году?} и 
\query{Кто был лауреатом Нобелевской премии мира в 1979 году?}.

Одной из важнейших причин этого является плохо предсказуемая селективность
конкретного запроса.
%По более строгим запросам поисковая система находит
%меньшее число результатов, но этим результатам можно доверять в большей
%степени.
Выбранное алгоритмом преобразование
может давать отличные результаты на
одном вопросе и, в то же время, приводить к получению запроса нулевой
селективности для другого запроса с очень похожими свойствами.
%из-за нерегулярности данных в Интернет.
Возможен и обратный эффект --- слишком неточный (из-за высокой селективности) запрос.

По этой причине естественно рассмотреть такое расширение QASM, %целевой функции 
которое вместо одного наиболее полезного запроса 
выбирает наиболее полезное подмножество запросов из
множества всех возможных преобразований исходного вопроса.
%Однако в такой переформулировке задача оптимизации становится значительно более 
%сложной из-за невозможности хорошо предсказать ``пересечение'' разных
%запросов. Поэтому мы ограничились промежуточным вариантом.
Однако решение этой оптимизационной задачи в общем случае представляется весьма
сложным из-за невозможности хорошо предсказать ``пересечение'' разных запросов.
Поэтому мы воспользовались эвристическим предположением, которое заключается в том,
что наиболее полезное подмножество запросов --- это подмножество всех преобразований
с предсказанной полезностью, превышающей некоторое пороговое значение.
%Алгоритм mQASM выбирает несколько запросов, но выбирает их по одному,
%т.е. построение множества сводится к последовательному решению 
%нескольких оптимизационных задач такого же вида как и в QASM.
На этой эвристике основывается алгоритм mQASM.

%Алгоритм mQASM выбирает несколько преобразований с наибольшей.
Построенные алгоритмом mQASM запросы
упорядочиваются по убыванию предсказанной селективности (см. раздел \ref{selectivity})
и последовательно выполняются.
Первым поисковой системе отправляется наиболее строгий, из еще неотправленных, запрос.
При этом на основании количества найденных по запросу документов оценивается качество поиска\footnote{
Подобная идея используется в системе Falcon~\cite{qa:Harabagiu}, 
где в зависимости от количества найденных по запросу документов,
запрос может быть ослаблен (если их слишком мало)
или усилен (если их слишком много) и повторно выполнен.}.
Если приемлемый уровень качества поиска достигнут --- то есть найдено достаточное количество документов ---
до того как все запросы отправлены, то
оставшиеся запросы можно уже не выполнять.

%Отметим, что, вообще говоря, целью этой работы является исследование того, 
%насколько хорошо можно выбирать множество преобразований, которое позволяет 
%получить наилучшую выборку документов, а также факторов от которых зависит 
%оптимальный выбор. 

%Описываемая модификация представляет собой промежуточный результат,
%который мы используем как основу для проведения анализа. В финальной версии 
%статьи вероятно будет описан ее уточненный вариант.

Более формально, mQASM генерирует по вопросу  $q$,
используя матрицу $\Theta$, построенную на этапе обучения,
все возможные запросы $\hat{q}$,
полученные последовательным применением атомарных операторов
%$(\mathcal{O}_{s_1},\ldots,\mathcal{O}_{s_{r_j}})$
к вопросу,
%упорядоченные наборы операций
%$(\mathcal{O}_{s_1},\ldots,\mathcal{O}_{s_r})$,
%преобразующие данный вопрос в запрос $\hat{q}$,
для которых {\em вероятность выбора} --- $P(\hat{q})$ ---
превышает некоторый порог $\gamma$: 
\begin{equation}\label{eq:pdef}
P(\hat{q}):=\max \prod_{k=0}^r p(\mathcal{O}_{s_k}|\mathcal{C}(q_{k-1})) \geq \gamma
\end{equation}
где $q_0 = q$, $q_{k}=\mathcal{O}_{s_k}(q_{k-1})$ и $\hat{q}=q_{s_r}$.
Максимум берется по всем последовательностям атомарных операторов
$(\mathcal{O}_{s_1},\ldots,\mathcal{O}_{s_r})$,
композиция которых в применении к исходному вопросу $q$
дает запрос $\hat{q}$ (может существовать более
одной такой последовательности).
$P(q)$ --- это и есть предсказанная полезность запроса.

Сгенерированные запросы образуют множество $\hat{Q}=\{\hat{q} | P(\hat{q})\geq\gamma\}$.
Для каждого $\hat{q} \in \hat{Q}$ вычисляется оценка его значимости $w_{\hat{q}}$,
которая определяет порядок выполнения запросов.
Запросы выполняются в порядке уменьшения значимости, до тех пор пока они не 
заканчиваются или не собрано достаточное количество документов (обозначим его $N_{\text{suff}}$).

Результаты $a_i$ выполнения запросов 
объединяются в единое множество 
(максимальное число учитываемых ответов на
каждый из запросов ограничено сверху той же константой $N_{\text{suff}}$)
и упорядочиваются по весу $w_{a_i}$, вычисляемому как: 
\[
w_{a_i} = \frac{N_{\text{suff}}-\mathit{rank}_{a_{i}}+1}{N_{\text{suff}}} * w_{\hat{q}}
\]
где $a_{i}$ --- это один из результатов ответа на запрос $\hat{q}$;
$rank_{a_i}$ --- порядковый номер $a_i$ в списке ответов на запрос $\hat{q}$
(то есть ранг, присвоенный документу $a_i$ поисковой системой по запросу $\hat{q}$).
Если один и тот же результат был получен по нескольким запросам,
то в качестве его веса в итоговом объединенном наборе берется наибольший из его весов.

%Таким образом вес документа в итоговом объединенном наборе
%в первую очередь
%определяется значимостью запроса, с помощью которого он был найден,
%и %, в меньшей степени, 
%рангом документа в соответствующей выдаче.
Таким образом, вес документа тем больше, чем ближе документ к началу итогового списка
и чем выше оценка значимости запроса, по которому он был получен.





\section{Прототип системы}

Для проведения экспериментальной оценки алгоритмов мы реализовали прототип
системы фактографического поиска для Веб.
В качестве базовой поисковой системы использовался
Яндекс\footnote{http://www.yandex.ru}.
Часть описываемых экспериментов мы провели также и
с использованием Google\footnote{http://www.google.com}.

\subsection{Атомарные операторы}

Мы рассматривали следующие атомарные операторы
преобразования запросов:

\begin{itemize}
\item Оператор $Identity$, сопоставляющий запросу его самого.
\item Несколько операторов удаления слов: удаления стоп-слов, вопросительных слов
и операторы удаления слов с частотой, превышающей определенный уровень.
\item Операторы склейки: между соседними словами запроса вставляется оператор синтаксиса
запросов Яндекс ``{\tt /n}'',
запрещающий Яндекс возвращать документы, в которых слова из запроса находятся на
расстоянии более {\tt n} слов друг от друга.
\item Оператор отмены морфологического анализа: перед каждым словом запроса
ставится восклицательный знак, запрещающий Яндекс возвращать документы, в которых
данное слово присутствует только в других морфологических формах.
\end{itemize}

Вероятно, что операторы замены слов на синонимы или обобщающие понятия (а
также добавления слов), подобные используемым в \cite{qa:radev:qasm}, могли
бы повысить качество поиска, но реализация этих операторов требует
использования качественных русскоязычных словарей синонимов или русскоязычного тезауруса.

Отметим, что мы рассматривали специфичные для языка запросов Яндекс
операторы для расширения набора операторов, и как оказалось, 
применение этих операторов положительно сказывается на качестве работы. 
Однако сами рассматриваемые алгоритмы не привязаны к какому-либо
конкретному языку запросов или поисковой системе.

\subsection{Свойства запросов}
В \cite{qa:radev:getting_answers} показывается, что определенные
свойства вопросов естественного языка, а именно: тип вопроса (ЛИЧНОСТЬ, МЕСТО и т.п.),
число слов в нем и число имен собственных,
влияют на способность поисковых систем отвечать на них, и вопросы с одинаковыми значениями
этих свойств можно обрабатывать сходным образом.

В нашем прототипе были использованы следующие свойства запросов:
тип вопроса,
число слов в запросе,
число имен собственных,
индикаторы применения операторов склейки и отмены морфологического анализа.



\subsection{Оценка качества поиска} \label{trdr}

Для оценки качества ответа на фактографический запрос часто
используются следующие метрики:

\begin{itemize}
\item {\bf MRR} (Mean Reciprocal Rank)~\cite{qa:TREC8:evaluation}: \\
Значение MRR для одного запроса $q$ равно:
$$MRR(q) = r^{-1},$$

где $r$ - ранг первого документа, содержащего правильный ответ на вопрос,
возвращенного системой среди первых пяти
($r=0$, если среди первых пяти нет содержащего правильный ответ).

Т.е. $MRR(q)$ может принимать одно из шести значений:
(1, 0.5, 0.33(3), 0.25, 0.2, 0), в зависимости от того, на какой позиции среди первых пяти
возвращен документ с правильным ответом.

%Среднее значение MRR по всем вопросам тестового набора вычисляется
%по формуле: $$MRR = \frac{1}{n} \sum_{i=1}^n RR_i$$
%где $$RR_i=\mathit{rank}_i^{-1}$$
%$\mathit{rank}_i$ - ранг первого документа, содержащего правильный ответ на $i$-й вопрос тестового набора,
%возвращенного системой среди первых пяти
%($RR_i=0$, если среди первых пяти нет содержащего правильный ответ);
%$n$ - число вопросов тестового набора.

Эта метрика несколько лет использовалась для
оценки качества фактографического поиска на конференции TREC.

\item {\bf TRDR} (Total Reciprocal Document Rank)~\cite{qa:radev:qasm}: \\
Эта метрика вычисляется как:
$$TRDR(q) = \sum_{i=1}^{n_{\text{corr}}} r_i^{-1}$$
где $n_{\text{corr}}$ - число документов, содержащих правильный ответ, среди первых
$N_\text{eval}$,
возвращенных поисковой системой по запросу $q$;
$r_i$ - ранг $i$-го документа, содержащего правильный ответ.

\end{itemize}

Для оценки общего качества поиска по метрикам MRR и TRDR вычисляются
их средние значения по всем вопросам тестового набора.

Алгоритмы QASM и mQASM при обучении используют
функцию оценки реального качества запроса $F(q)$ (см. раздел~\ref{qasm:learning}).
При выборе метрики, используемой в качестве $F(q)$, мы руководствовались
следующими соображениями.

При использовании MRR
исходят из того, что для пользователя очень существенно, чтобы правильный ответ
был первым в списке документов, поэтому
MRR выше, когда система возвращает только один
правильный ответ, но на первом месте,
чем когда все ответы, кроме первого, в списке результатов правильные.
Но в случае, когда результаты поиска документов по сформулированным
системой на этапе преобразования запросам
передаются другой компоненте системы для выделения ответов,
количество документов, содержащих правильный ответ,
может иметь важное значение, поскольку многие системы
при выделении ответов пользуются избыточностью и склонны выбирать
ответы, чаще встречающиеся в результатах поиска.
Поэтому метрика TRDR, отличающаяся от MRR тем, что при ее вычислении учитывается
не только первый правильный ответ, но и последующие,
лучше подходит для оценки качества преобразования запросов,
тогда как MRR лучше подходит для оценки качества поиска на выходе
полноценной системы фактографического поиска, выделяющей ответы из
найденных документов.
В частности, проведенные нами эксперименты показали 5\%-ное
ухудшение качества поиска по
метрике MRR и 8.4\%-ное по метрике TRDR при использовании при обучении MRR
по сравнению с TRDR.

Поэтому для оценки реального качества запросов мы использовали метрику TRDR:
$$F(q) = TRDR(q).$$


\subsection{Оценка селективности запроса} \label{selectivity}
Оценка относительной селективности запроса, построенного алгоритмом mQASM,
в нашем прототипе выполнялась следующим образом.

  Каждому атомарному оператору был сопоставлен некоторый
  коэффициент селективности $s_j$, больший или меньший 1. 
  Оператор $Identity$, примененный к запросу, не изменяет
  его селективность (поэтому коэффициент селективности оператора $Identity$ равен 1),
  операторы удаления увеличивают, остальные
  уменьшают.

  Вес запроса $\hat{q}$ определялся по формуле:
  $$w_{\hat{q}}=\prod_j s_j^{-1}$$
  где $s_j$ - коэффициенты селективности атомарных операторов,
  последовательным применением которых к исходному вопросу был получен запрос $\hat{q}$.

  %К сожалению, из-за того, что использовавшиеся нами поисковые системы 
  %учитывают в выводимой статистике 
  %несколько уровней соответствия найденных документов запросу
  %(строгое/нестрогое), то для разумной экспериментальной 
  %оценки селективности операторов необходимо загрузить большое количество
  %результатов (что не очень приветствуется поисковыми системами). 
  %поэтому 

  Как оказалось, оценка реальных значений коэффициентов селективности
  операторов слишком трудоемка из-за некоторых особенностей Яндекс\footnote{
      А именно, из-за того, что
      Яндекс различает несколько уровней соответствия найденных документов запросу:
      строгих и нестрогих.
%      Из-за этого для корректной оценки селективности запроса приходится
%      загружать с сайта Яндекс все страницы с результатами поиска по запросу,
%      что требует слишком больших ресурсов для запросов с высокой селективностью.
  },
  поэтому в прототипе использовались эвристические значения этих коэффициентов: 
  \begin{itemize}
  \item 1 для оператора $Identity$,
  \item от 1.05 до 2 для разных операторов удаления слов,
  \item 0.7 и 0.8 для двух операторов склейки и 0.8 для оператора отмены морфологического анализа. 
  \end{itemize}


\subsection{Оценка значимости запроса} \label{queryweights}

Алгоритм mQASM (см. раздел \ref{mqasm})
использует оценки значимости $w_{\hat{q}}$ запроса $\hat{q}$ 
для определения порядка выполнения запросов,
%(что косвенным образом определяет, какие документы в конечном счете попадут в итоговый результат)
кроме того оценки значимости запросов влияют на итоговые веса результатов поиска.

Мы рассматривали несколько разных вариантов взвешивания запросов: 

\begin{itemize}
\item {\bf Равные веса}\\
  Всем запросам присваивается один и тот же вес (равный 1).
\item {\bf Оценка вероятности выбора}\\
  В этом случае вес $w_{\hat{q}}$ запроса $\hat{q}$ считается равным значению
 $P(\hat{q})$, определяемому формулой \ref{eq:pdef}.
\item {\bf Оценка селективности}\\
  В этом случае весу запроса $\hat{q}$ присваивалась оценка селективности $\hat{q}$.
\end{itemize}

В каждом из этих вариантов веса нормализовались,
так чтобы наибольший вес запроса был равен 1.

\section{Экспериментальный анализ}

\begin{table*}[tb]
\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
Подход & MRR & TRDR & Ответы \\
\hline
\hline
Яндекс & 0.436 & 0.938 & 31 (77.5\%) \\
\hline
QASM &  0.498 (+14.2\%) & 0.992 (+5.8\%) & 29 (72.5\%) \\
mQASM & 0.519 (+19.0\%) & 1.155 (+23.1\%) & 33 (82.5\%)  \\
\hline
oQASM & 0.678 (+55.3\%) & 1.457 (+55.2\%) & 35 (87.5\%) \\
\hline
\end{tabular}
\caption{Общее качество поиска}
\label{table:efficiency}
\end{center}
\end{table*}


Целью экспериментального анализа являлось изучение поведения алгоритмов
QASM и mQASM в сравнении с максимально достижимым результатом,
для определения факторов, от которых зависит оптимальный выбор.

\subsection{Набор данных}
Для обучения системы использовался набор из 60 пар (вопрос,ответ) типа ЛИЧНОСТЬ,
из которых 30 были получены из журнала запросов Яндекс,
и 30 были придуманы искусственно.

Общая эффективность оценивалась на наборе из 40 вопросов того же типа
(все 40 были получены из журнала запросов Яндекс).
Наборы вопросов для обучения и для оценки не пересекались.

Решение ограничиться одним типом было обусловлено сложностью задачи создания
качественных тренировочного и тестового наборов вопросов.
%которые должны быть разными для каждого из типов вопросов. 
Других принципиальных ограничений, препятствующих оценке других типов 
фактографических вопросов, в рамках описываемого прототипа нет. 

Отметим, что для запросов других типов вероятно
изменение наблюдаемых закономерностей.

\subsection{Критерии оценки качества поиска}
Для оценки качества поиска использовались три метрики:
\begin{itemize}
\item метрика MRR,
\item метрика TRDR,
\item число вопросов, на которые системе удалось найти правильный ответ.
\end{itemize}

Оценка выполнялась автоматически:
документ, возвращенный системой, засчитывался как правильный ответ,
если он содержал соответствие
одному из нескольких регулярных выражений, заданных заранее для каждого
из вопросов тестового и тренировочного наборов.

При вычислении всех метрик на наличие правильного ответа проверялись
только первые 20 возвращенных системой документов
(т.е. $N_{\text{eval}}=20$).



\subsection{Общее качество поиска}


В таблице~\ref{table:efficiency} приведены результаты оценки общего качества
поиска, полученные при использовании 
алгоритмов QASM, mQASM и oQASM
на исходном наборе данных
(т.е. при одном из разбиений набора вопросов на вопросы для обучения и оценки).

В ней также для сравнения приведены оценки
качества поиска, полученные при выполнении как запросов Яндекс
немодифицированных вопросов тестового набора.

%Кроме значений MRR и TRDR для каждого из подходов в таблице приведено число
%правильных ответов, которые удалось найти системе (ответ засчитывался, если
%среди одного из первых 20-ти документов, возвращенных системой в итоговом
%списке, был хотя бы один, содержащий правильный ответ).

Как видно из таблицы, максимально достижимый результат (oQASM)
по обеим метрикам MRR и TRDR более чем на 50\% превышает
результат, полученный при выполнении непреобразованных вопросов.
Это подтверждает гипотезу о том, что использование подобных преобразований 
запросов может значительно повысить качество поиска.
Однако результаты QASM и mQASM значительно отстают от максимально достижимого.

QASM превосходит Яндекс по метрикам
MRR и TRDR, но проигрывает по числу найденных правильных ответов. Это
объясняется тем, что QASM имеет склонность выбирать для вопроса слишком
строгое преобразование, которое хорошо подошло для каких-то вопросов
тренировочного набора с такими же свойствами. И если по преобразованному
запросу находятся документы, то среди них документы, содержащие правильные
ответы, имеют высокий ранг (а отсюда и высокий MRR/TRDR). Но в некоторых
случаях множество документов, удовлетворяющих слишком строгому
преобразованному запросу, пусто. Яндекс же почти всегда возвращает непустое
множество ответов, но искомые документы не всегда имеют высокий ранг.

Модифицированный алгоритм, благодаря использованию
кроме строгих формулировок запросов и менее строгих,
решает проблему QASM и демонстрирует лучшее
качество, по сравнению с Яндекс и QASM по всем метрикам.

Однако текущие результаты mQASM пока также значительно уступают максимально
достижимым: угадать наилучшее преобразование алгоритму удалось только для
19-ти вопросов тестового набора. Вероятными причинами этого являются:
нерегулярность данных в Интернет, недостаточная обученность модели (слишком
маленький набор вопросов для обучения) и недостаточно хорошее %детальное
описание запросов с помощью используемого набора свойств, что не позволяет
адекватно обучиться различиям между запросами.

Отметим также, что даже при полном переборе всех возможных преобразований и
выборе наилучшего, система смогла найти документы, содержащие правильные
ответы, только для 35 вопросов из 40. Этот факт может быть объяснен тем, что
документы, содержащие правильные ответы на неотвеченные вопросы, отсутствуют
в проиндексированной Яндексом части Интернет, или же им по каким-то причинам
присваивается слишком низкий ранг и никакое преобразование вопроса не
помогает им оказаться среди первых
$N_{\text{suff}}$ (в наших экспериментах $N_{\text{suff}}=20$)
документов при ранжировании Яндексом результатов поиска.


\subsection{Схемы взвешивания запросов}

\begin{table*}[tb]
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
Веса запросов & MRR & TRDR \\
\hline
\hline
Равные & 0.479 & 1.059 \\
Вероятность выбора & 0.485(+1.2\%) & 1.134(+7.0\%) \\
Оценка селективности & 0.519(+8.4\%) & 1.155(+9.0\%) \\
\hline
\end{tabular}
\caption{Выбор схемы взвешивания запросов для mQASM.}
\label{table:weighting}
\end{center}
\end{table*}

\begin{table*}[bt]
\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
Без какого оператора? & MRR & TRDR & Ответы \\
\hline
\hline
Со всеми операторами & 0.519 & 1.155 & 33 \\
 отмены морфологического разбора & 0.437 (-15.8\%)  & 1.001 (-13.3\%) & 30 \\
 склейки & 0.485 (-6.6\%) & 1.093 (-5.3\%) & 32 \\
 удаления & 0.396 (-23.7\%) & 0.967 (-16.2\%) & 32 \\
\hline
\end{tabular}
\caption{Оценка важности операторов (mQASM)}
\label{table:operators}
\end{center}
\end{table*}

\begin{table*}[tb]
\begin{center}
\begin{tabular}{|l|c|c|c|}
\hline
Без какого свойства? & MRR & TRDR & Ответы \\
\hline
\hline
Со всеми свойствами & 0.519 & 1.155 & 33 \\
 числа имен собственных & 0.420 (-19.0\%) & 0.886 (-23.2\%) & 27 \\
 числа слов & 0.457 (-11.9\%) & 1.056 (-8.5\%) & 32 \\
 индикаторов & 0.445 (-14.3\%) & 1.025 (-11.2\%) & 32 \\
%Фиктивное & 0.436 (-16.0\%) & 31 \\
\hline
\end{tabular}
\caption{Оценка важности свойств (для mQASM)}
\label{table:props}
\end{center}
\end{table*}


%Взвешивание запросов используется в модифицированном QASM для оценки их значимости.
%Веса запросов влияют на порядок их выполнения и на итоговые веса найденных по ним документов.
В таблице~\ref{table:weighting} представлены результаты экспериментов по
сравнению схем взвешивания запросов для модифицированного QASM,
описанных в разделе~\ref{queryweights}.

Как и ожидалось, использование равных весов приводит к худшему результату:
равноправие запросов обуславливает ``зашумление'' итогового набора
документов при слиянии результатов этих запросов.

То, что оценка селективности запроса оказывается лучше оценки 
вероятности выбора запроса %также вполне объяснимо.
%То, что данное преобразование вопроса имеет высокую вероятность 
%выбора никак не характеризует его селективность.
%
% Это я не понимаю, поэтому вернул старый кусок:
%
%Как следствие, результат обработки такого запроса может 
%содержать много документов, которые получат большой вес, и 
%поэтому будут преобладать в общем результате, делая его 
%похожим на результат оригинального QASM.
можно объяснить тем, что наиболее вероятный запрос %, к сожалению,
не всегда является наилучшим: иногда он слишком строг для вопроса
(и тогда по нему не находятся никакие документы),
иногда слишком ослаблен (тогда находится большое число неподходящих).
Именно в тех случаях, когда он слишком ослаблен, присваивание ему большего
веса, чем наилучшему, и сказывается отрицательно на качестве поиска
в схеме взвешивания, основанной на оценке вероятности выбора,
поскольку при этом большой вес в итоговом списке могут получить многие
неподходящие документы.


\subsection{Важность операторов и свойств}

Для того чтобы понять, насколько выбор множества используемых операторов 
и свойств вопроса влияет на качество получаемых результатов, мы поставили две
группы экспериментов.

В обоих случаях мы повторяли базовый эксперимент, 
результаты которого обсуждались в разделе 6.2, но 
варьировали множества используемых операторов и свойств вопроса.

В первом случае мы повторяли экперимент, поочередно исключая из модели один
из операторов. Как видно из результатов в таблице~\ref{table:operators},
наиболее заметное влияние на результат оказывают операторы удаления и морфологического
разбора, причем отмена последнего сказывается на количестве найденных
ответов, а не только на их относительном расположении.

Во второй группе экспериментов мы поочередно исключали из модели 
отдельные свойства, характеризующие вопрос (см. таблицу~\ref{table:props}). 
Наиболее заметное падение эффективности наблюдалось при исключении 
информации о числе имен собственных.


\subsection{Анализ устойчивости}

Результаты оценки общего качества поиска, подобные представленным в
таблице~\ref{table:efficiency}, зависят от используемых наборов вопросов для
обучения и оценки, и прежде чем делать выводы,
важно оценить стабильность этих результатов.

Вне зависимости от подхода абсолютное качество поиска сильно варьируется в
зависимости от набора данных, поэтому усреднение абсолютных величин оценок
качества поиска не позволяет сделать осмысленные выводы о стабильности
результатов. Вместо этого мы оценивали стабильность выводов о
превосходстве каждого из подходов над другими.

Традиционно выводы о превосходстве системы поиска $A$ над системой $B$ на
заданном наборе данных делаются на основе измеренных оценок качества поиска
по некоторому набору информационных потребностей.~\cite{irg:eval}
При этом разница, которая не превышает определенный {\em уровень значимости},
считается несущественной, т.е. считается, что ни одна из систем не превосходит другую,
и засчитывается ничья.

В этой работе оценивалась стабильность результатов
в зависимости от выбранного разбиения множества вопросов
на наборы для обучения и оценки.
Для этого вопросы набора данных случайным образом разделялись на набор для обучения
и набор для оценки в том же соотношении 60/40.
Всего было построено 40 случайных разбиений,
для каждого из которых были полностью выполнены этапы обучения и оценки.

\begin{table*}
\begin{center}
\begin{tabular}{|r|cc|cc|cc|}
\hline
    &  \multicolumn{2}{c|}{MRR} &  \multicolumn{2}{c|}{TRDR} &  \multicolumn{2}{c|}{Ответы} \\
\hline
    & Яндекс & QASM & Яндекс & QASM & Яндекс & QASM  \\
\hline
%\hline
QASM         &  1:30:9   &   -           &   2:29:9  &  -              &  0:40:0   &  -  \\
mQASM  &  17:3:20  & 36:0:4   &    37:0:3   & 40:0:0   &  5:1:35  & 40:0:0  \\
\hline
\end{tabular}
\caption{Стабильность выводов о превосходстве (уровень значимости 5\%)}
\label{table:stability}
\end{center}
\end{table*}

Результаты экспериментов представлены в таблице~\ref{table:stability}:
в каждой ячейке таблицы стоят разделенные двоеточием количества разбиений,
на которых метод, указанный в заголовке строки,
соответственно, превзошел, уступил или показал ничейный результат
по сравнению с методом, указанным в заголовке столбца.

Как видно из таблицы, множественный QASM в 36 случаях из 40 превзошел результат Яндекс по
оценке MRR, а в остальных 4-х вывод о превосходстве сделать невозможно, так
как разница результатов не превышает уровня значимости.

QASM часто проигрывает Яндекс вне зависимости от
выбранной меры оценки. Тем самым, можно констатировать, что несмотря на
позитивный эффект в некоторых случаях, QASM не дает стабильного улучшения и
может привести к заметному ухудшению результата.

Множественный QASM ведет себя заметно лучше --- он всегда выигрывает у
оригинального QASM. Кроме того, он заметно выигрывает у Яндекс по TRDR, хотя
по MRR и числу ответов выигрыш не столь значителен. 
Другими словами, множественный QASM 
в этих экспериментах стабильно улучшал качество итогового ранжирования.

Отметим, что хотя подобный анализ стабильности и повышает 
обоснованность наблюдений, но его результаты могут зависеть от 
параметров модели (таких как наборы операторов или свойств) 
и используемого набора данных. Мы планируем в дальнейшем исследовать эти зависимости.

\section{Заключение}

Огромный объем Веб делает ее весьма привлекательной коллекцией для
поиска ответов на фактографические запросы.  При обработке таких запросов в
контексте Веб важную роль играет качество преобразования вопросов на
естественном языке в запросы поисковой системы общего назначения.

В этой работе исследовались возможности использования статистических
подходов к преобразованию фактографических запросов
на основе алгоритма QASM и его модификаций.

Проведенный экспериментальный анализ показал, что применение
преобразований, допускаемых моделью QASM, может значительно повысить 
качество результатов. Оригинальный алгоритм QASM 
в наших экспериментах показал нестабильные результаты, 
но его модификация mQASM вела себя значительно более стабильно.

Основной целью наших исследований является определение и 
характеризация факторов, влияющих на итоговую эффективность 
преобразования запросов. Некоторые результаты приведены в этой 
статье, но эти вопросы конечно же требуют дальнейшего 
более тщательного и масштабного исследования.

\bibliographystyle{plain}
\bibliography{qa}

\bigskip

\section*{\center Statistical Query Transformations for Question Answering in the Web}

\begin{center}
Ilya Boyandin, Igor Nekrestyanov

\bigskip

{\bf Abstract}
\end{center}

We consider the problem of query transformation for question answering in
the Web. The goal of such transformations is
to construct a query for a traditional Web search engine
given a factual natural language question
so that the first several documents returned by the search engine by this query
contain the correct answer to the original question.

In this paper we analyse a statistical query transformation algorithms based
on the QASM~\cite{qa:radev:qasm} model, and evaluate the search quality of
these algorithms on a corpus of correct Russian-language questions
from the log of the Yandex search engine.

\end{document}
